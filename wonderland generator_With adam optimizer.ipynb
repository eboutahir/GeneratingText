{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wonderland generator_adam | BOUTAHIR.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"XT0jJP7B-4YZ","colab_type":"text"},"cell_type":"markdown","source":["# Génération de texte avec les réseaux de neurones récurrents LSTM avec Keras"]},{"metadata":{"id":"qDbpAiUS-4Yd","colab_type":"text"},"cell_type":"markdown","source":["#### Par : BOUTAHIR Mohamed Khalifa [ MASTER IPS ]\n","\n","---\n","\n","\n","#### Data : nous allons utiliser un livre de l'enfance comme Data: \"Alice's Adventures in Wonderland de Lewis Carroll\" . https://gist.github.com/phillipj/4944029\n","\n","\n","---\n","\n","\n","#### Le but de projet est de predire une suite où un nouveau scenario pour ce livre .L'utilisation des réseaux LSTM est pour apprendre des séquences de personnages d’Alice au pays des merveilles. Et par la suite le modèle va générer des nouvelles séquences de caractères.\n","<img src=\"https://i.ibb.co/MVJLz2B/wonderland.jpg\" alt=\"wonderland\" border=\"0\" width=\"400\">"]},{"metadata":{"id":"Z2uqEXh4-4Yf","colab_type":"text"},"cell_type":"markdown","source":["## 1- Importation des bibliothèques et le jeu de données"]},{"metadata":{"id":"IzKabpN5-4Yi","colab_type":"code","outputId":"b96c2092-bd18-4258-d753-2a5e1f5d911e","executionInfo":{"status":"ok","timestamp":1550281598936,"user_tz":-60,"elapsed":3721,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import sys\n","import numpy\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"aOOymU2m-4Y0","colab_type":"text"},"cell_type":"markdown","source":["# 2- Préparation de l’ensemble de données"]},{"metadata":{"id":"LbAVrhca-4Y4","colab_type":"text"},"cell_type":"markdown","source":["#### Demande d'accés au drive pour faire l'importation de fichier depuis le\n","\n"]},{"metadata":{"id":"V6K7gjen_FS9","colab_type":"code","outputId":"dc818d9b-a8b5-419b-baaa-b1d20e1f253b","executionInfo":{"status":"ok","timestamp":1550281694300,"user_tz":-60,"elapsed":62886,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('DeepLearning.txt/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at DeepLearning.txt/\n"],"name":"stdout"}]},{"metadata":{"id":"w3fARIUV1I4T","colab_type":"text"},"cell_type":"markdown","source":["#### Importation du fichier texte et le convertir en minuscule"]},{"metadata":{"id":"z-AxlQ4N-4Y9","colab_type":"code","colab":{}},"cell_type":"code","source":["filename = \"//content//DeepLearning.txt//My Drive//Colab Notebooks//wonderland generator//wonderland.txt\"\n","text = open(filename).read()\n","text = text.lower()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2oxTQzvC-4ZE","colab_type":"text"},"cell_type":"markdown","source":["#### Detecter les caractères de jeu de donnees et les classer \n"," Nous ne pouvons pas modéliser les caractères directement dans le réseau de neurones, nous devons plutôt convertir les caractères en entiers."]},{"metadata":{"id":"iC4-vhGB-4ZG","colab_type":"code","colab":{}},"cell_type":"code","source":["chars = sorted(list(set(text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LCPfVzc_-4ZN","colab_type":"code","outputId":"e159d50b-c608-4955-c952-854320a76e35","executionInfo":{"status":"ok","timestamp":1550281781945,"user_tz":-60,"elapsed":1534,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["print(char_to_int)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '0': 11, '3': 12, ':': 13, ';': 14, '?': 15, '[': 16, ']': 17, '_': 18, '`': 19, 'a': 20, 'b': 21, 'c': 22, 'd': 23, 'e': 24, 'f': 25, 'g': 26, 'h': 27, 'i': 28, 'j': 29, 'k': 30, 'l': 31, 'm': 32, 'n': 33, 'o': 34, 'p': 35, 'q': 36, 'r': 37, 's': 38, 't': 39, 'u': 40, 'v': 41, 'w': 42, 'x': 43, 'y': 44, 'z': 45}\n"],"name":"stdout"}]},{"metadata":{"id":"1d2bD3dh-4ZY","colab_type":"text"},"cell_type":"markdown","source":["#### Calcule le nombre total des caractères  de texte et le nombre des caractères "]},{"metadata":{"id":"jdtlpw3r-4Zb","colab_type":"code","outputId":"61a7496c-9fe7-451c-e6c2-fea575a39510","executionInfo":{"status":"ok","timestamp":1550281785581,"user_tz":-60,"elapsed":987,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["n_chars = len(text)\n","n_vocab = len(chars)\n","print(\"Total Characters: \", n_chars)\n","print(\"Total Vocab: \", n_vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total Characters:  148574\n","Total Vocab:  46\n"],"name":"stdout"}]},{"metadata":{"id":"nnesTXBK-4Zn","colab_type":"text"},"cell_type":"markdown","source":["# 2- Creation de réseau de neurones"]},{"metadata":{"id":"LgQwWj23-4Zq","colab_type":"text"},"cell_type":"markdown","source":["Nous allons diviser le texte du livre en sous-séquences d'une longueur fixe de 100 caractères. <br>\n","Chaque modèle d'apprentissage du réseau est composé de 100 pas de temps d'un caractère (X) suivis d'une sortie de caractère (y)."]},{"metadata":{"id":"y0n8GSrg-4Zt","colab_type":"code","colab":{}},"cell_type":"code","source":["seq_length = 100\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","    seq_in = text[i:i + seq_length]\n","    seq_out = text[i + seq_length]\n","    dataX.append([char_to_int[char] for char in seq_in])\n","    dataY.append(char_to_int[seq_out])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rO-L60x2-4Zz","colab_type":"text"},"cell_type":"markdown","source":["On va calculer le nombre des échantillons qu'on dans le \"X\""]},{"metadata":{"id":"iJ-iZKZD-4Z2","colab_type":"code","outputId":"5dfc00fe-fe48-45d6-f5ce-7847baeb75de","executionInfo":{"status":"ok","timestamp":1550281793592,"user_tz":-60,"elapsed":1065,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["n_patterns = len(dataX)\n","print(\"Total Patterns: \", n_patterns)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total Patterns:  148474\n"],"name":"stdout"}]},{"metadata":{"id":"pq_XKEaB-4aA","colab_type":"text"},"cell_type":"markdown","source":["Maintenant que nous avons préparé nos données d’entraînement, nous devons les transformer pour qu’elles puissent être utilisées avec Keras.\n","\n","Nous devons d’abord transformer la liste des séquences d’entrée sous la forme [échantillons, pas de temps, fonctions] pour qu'on puisse les entrés pour notre réseau LSTM."]},{"metadata":{"id":"1tYk6l0U-4aC","colab_type":"code","colab":{}},"cell_type":"code","source":["X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n","\n","X = X / float(n_vocab)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gdah-jiXojTn","colab_type":"text"},"cell_type":"markdown","source":["Chaque valeur y est convertie en un vecteur de longueur 47, plein de zéros, à l’exception d’un 1 dans la colonne correspondant à la lettre (nombre entier représentatif par chaque letre).."]},{"metadata":{"id":"6m8tJaZo-4aK","colab_type":"code","colab":{}},"cell_type":"code","source":["y = np_utils.to_categorical(dataY)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S9BgZLq-oqrN","colab_type":"text"},"cell_type":"markdown","source":["# 3- Définir le modèle LSTM :"]},{"metadata":{"id":"2pHOU9X4ol4d","colab_type":"text"},"cell_type":"markdown","source":["Le modéle LSTM utilise 256 unités de mémoire des couches cachées, il utilise aussi Dropout avec une probabilité de 20  \n","\n","---\n","Nous avons utilisé aussi une fonction d'activation **Softmax** en couche de sortie \n","\n","---\n","\n","Le model utilise ici l'algorithme d'optimisation **rmsprop** ."]},{"metadata":{"id":"dmWrivHQ-4aW","colab_type":"code","outputId":"10123e31-e820-4142-b380-64776211d173","executionInfo":{"status":"ok","timestamp":1550281806251,"user_tz":-60,"elapsed":1392,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"cell_type":"code","source":["# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"metadata":{"id":"ECcaPBzZo1Ig","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","En raison de la lenteur de l'execution du model et pour l'optimisation, nous allons utiliser un point de contrôle de modèle pour enregistrer tous les poids du réseau à archiver chaque fois qu'une amélioration de la perte est observée à la fin de l'époque. Nous utiliserons le meilleur ensemble de poids (perte minimale) pour instancier notre modèle génératif dans la section suivante.\n","\n","\n","---\n","\n"]},{"metadata":{"id":"rm1QHX2V-4ac","colab_type":"code","colab":{}},"cell_type":"code","source":["# define the checkpoint\n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uXn2T_oto493","colab_type":"text"},"cell_type":"markdown","source":["On fait ici une autre transformation des entiers à des caractéres pour qu'on puisse par la suite génerer le texte."]},{"metadata":{"id":"_8JSdAn9-4al","colab_type":"code","colab":{}},"cell_type":"code","source":["int_to_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5vomi6efo97n","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","Nous pouvons maintenant adapter notre modèle aux données. Nous utilisons ici un nombre modeste de 20 époques et une grande batch size de 128 patterns .\n","\n","---\n","\n"]},{"metadata":{"scrolled":true,"id":"q9_qQx0H-4ar","colab_type":"code","outputId":"716c6a34-aebb-437b-b103-2f61e76e765b","executionInfo":{"status":"ok","timestamp":1550314670832,"user_tz":-60,"elapsed":32753861,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":1456}},"cell_type":"code","source":["model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","148474/148474 [==============================] - 1563s 11ms/step - loss: 2.9408\n","\n","Epoch 00001: loss improved from inf to 2.94077, saving model to weights-improvement-01-2.9408.hdf5\n","Epoch 2/20\n","148474/148474 [==============================] - 1657s 11ms/step - loss: 2.7063\n","\n","Epoch 00002: loss improved from 2.94077 to 2.70625, saving model to weights-improvement-02-2.7063.hdf5\n","Epoch 3/20\n","148474/148474 [==============================] - 1651s 11ms/step - loss: 2.6000\n","\n","Epoch 00003: loss improved from 2.70625 to 2.60001, saving model to weights-improvement-03-2.6000.hdf5\n","Epoch 4/20\n","148474/148474 [==============================] - 1663s 11ms/step - loss: 2.5304\n","\n","Epoch 00004: loss improved from 2.60001 to 2.53044, saving model to weights-improvement-04-2.5304.hdf5\n","Epoch 5/20\n","148474/148474 [==============================] - 1658s 11ms/step - loss: 2.4708\n","\n","Epoch 00005: loss improved from 2.53044 to 2.47081, saving model to weights-improvement-05-2.4708.hdf5\n","Epoch 6/20\n","148474/148474 [==============================] - 1655s 11ms/step - loss: 2.4181\n","\n","Epoch 00006: loss improved from 2.47081 to 2.41807, saving model to weights-improvement-06-2.4181.hdf5\n","Epoch 7/20\n","148474/148474 [==============================] - 1647s 11ms/step - loss: 2.3704\n","\n","Epoch 00007: loss improved from 2.41807 to 2.37041, saving model to weights-improvement-07-2.3704.hdf5\n","Epoch 8/20\n","148474/148474 [==============================] - 1641s 11ms/step - loss: 2.3271\n","\n","Epoch 00008: loss improved from 2.37041 to 2.32714, saving model to weights-improvement-08-2.3271.hdf5\n","Epoch 9/20\n","148474/148474 [==============================] - 1636s 11ms/step - loss: 2.2811\n","\n","Epoch 00009: loss improved from 2.32714 to 2.28114, saving model to weights-improvement-09-2.2811.hdf5\n","Epoch 10/20\n","148474/148474 [==============================] - 1629s 11ms/step - loss: 2.2420\n","\n","Epoch 00010: loss improved from 2.28114 to 2.24197, saving model to weights-improvement-10-2.2420.hdf5\n","Epoch 11/20\n","148474/148474 [==============================] - 1625s 11ms/step - loss: 2.2032\n","\n","Epoch 00011: loss improved from 2.24197 to 2.20317, saving model to weights-improvement-11-2.2032.hdf5\n","Epoch 12/20\n","148474/148474 [==============================] - 1627s 11ms/step - loss: 2.1691\n","\n","Epoch 00012: loss improved from 2.20317 to 2.16913, saving model to weights-improvement-12-2.1691.hdf5\n","Epoch 13/20\n","148474/148474 [==============================] - 1627s 11ms/step - loss: 2.1307\n","\n","Epoch 00013: loss improved from 2.16913 to 2.13074, saving model to weights-improvement-13-2.1307.hdf5\n","Epoch 14/20\n","148474/148474 [==============================] - 1646s 11ms/step - loss: 2.0920\n","\n","Epoch 00014: loss improved from 2.13074 to 2.09197, saving model to weights-improvement-14-2.0920.hdf5\n","Epoch 15/20\n","148474/148474 [==============================] - 1646s 11ms/step - loss: 2.0607\n","\n","Epoch 00015: loss improved from 2.09197 to 2.06068, saving model to weights-improvement-15-2.0607.hdf5\n","Epoch 16/20\n","148474/148474 [==============================] - 1634s 11ms/step - loss: 2.0280\n","\n","Epoch 00016: loss improved from 2.06068 to 2.02798, saving model to weights-improvement-16-2.0280.hdf5\n","Epoch 17/20\n","148474/148474 [==============================] - 1632s 11ms/step - loss: 1.9985\n","\n","Epoch 00017: loss improved from 2.02798 to 1.99852, saving model to weights-improvement-17-1.9985.hdf5\n","Epoch 18/20\n","148474/148474 [==============================] - 1639s 11ms/step - loss: 1.9694\n","\n","Epoch 00018: loss improved from 1.99852 to 1.96938, saving model to weights-improvement-18-1.9694.hdf5\n","Epoch 19/20\n","148474/148474 [==============================] - 1644s 11ms/step - loss: 1.9411\n","\n","Epoch 00019: loss improved from 1.96938 to 1.94112, saving model to weights-improvement-19-1.9411.hdf5\n","Epoch 20/20\n","148474/148474 [==============================] - 1630s 11ms/step - loss: 1.9190\n","\n","Epoch 00020: loss improved from 1.94112 to 1.91903, saving model to weights-improvement-20-1.9190.hdf5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f10e67ef0f0>"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"VR9eexQApEX0","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","\n","---\n","\n","\n","*   **Nous avons testé le modele dans plusieurs platformes pour trouvé la platforme la plus rapide pour entrainer notre modéle et voila les resultats qu'on a trouvé**\n","\n","\n","---\n","\n","\n"]},{"metadata":{"id":"qugbaD1q-4a5","colab_type":"text"},"cell_type":"markdown","source":["<table>\n","    <tr>\n","        <td>Platform d'essai</td>\n","        <td>Temps en (s) pour chaque itération</td>\n","    </tr>\n","    <tr>\n","        <td>GOOGLE COLAB</td>\n","        <td>850s</td>\n","    </tr>\n","    <tr>\n","        <td>MY LAPTOP</td>\n","        <td>2000s</td>\n","    </tr>\n","    <tr>\n","        <td>COCALC : https://cocalc.com</td>\n","        <td>5000s</td>\n","    </tr>\n","    <tr>\n","        <td>AZURE NOTEBOOK</td>\n","        <td>24394s</td>\n","    </tr>\n","</table>"]},{"metadata":{"id":"yHx-izh_-4a8","colab_type":"text"},"cell_type":"markdown","source":["GOOGLE COLAB itération : \n","<img src=\"https://i.ibb.co/xjtWVSJ/Capture3.png\" alt=\"Capture3\" border=\"0\">"]},{"metadata":{"id":"XlyuoTtT-4bB","colab_type":"text"},"cell_type":"markdown","source":["AZURE itération :\n","<img src=\"https://i.ibb.co/S3qNnzY/Capture.png\" alt=\"Capture\" border=\"0\">"]},{"metadata":{"id":"o5-HxNGC-4bE","colab_type":"text"},"cell_type":"markdown","source":["COLALC itération : \n","<img src=\"https://i.ibb.co/ZKWkPzj/Capture2.png\" alt=\"Capture2\" border=\"0\">"]},{"metadata":{"id":"8zIr-Nn1h7Xq","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","Nous avons testé deux fonctions d'optimization : \n","\n","\n","*   Avec ADAM : le model a reduit le Loss de **3.2198** à **1.9190**\n","*   Avec RMSPROP : le model a reduit le Loss de **3.3150** à **1.9197**\n","\n"]},{"metadata":{"id":"CbG8WCDFpLUR","colab_type":"text"},"cell_type":"markdown","source":["# 4- Le resultat finale : "]},{"metadata":{"id":"2LSuGSNy-4bQ","colab_type":"code","outputId":"c250e1f7-5b22-4525-8b62-ab16aa003af4","executionInfo":{"status":"ok","timestamp":1550323077625,"user_tz":-60,"elapsed":9635,"user":{"displayName":"Mohamed Khalifa Boutahir","photoUrl":"","userId":"14016981202865798080"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["# pick a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print(\"Seed:\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n","# generate characters\n","for i in range(500):\n","    x = numpy.reshape(pattern, (1, len(pattern), 1))\n","    x = x / float(n_vocab)\n","    prediction = model.predict(x, verbose=0)\n","    index = numpy.argmax(prediction)\n","    result = int_to_char[index]\n","    seq_in = [int_to_char[value] for value in pattern]\n","    sys.stdout.write(result)\n","    pattern.append(index)\n","    pattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Seed:\n","\" id the king.  `when did you\n","begin?'\n","\n","  the hatter looked at the march hare, who had followed him int \"\n"," the was of the wordd     `ii soon hi the mort aro a lan ' said the doypouse.\n","`and thet so soe toine of the sooe.    the hatter was toe birttenf thet she was notting an in soohe    the hurphon taid to the hocve    `thet io wou doond to the fore   the hatter senlied. `and thet soee of the sorele ' \n","  `i c varhin a gitt wite tou,' said the caterpillar.\n","\n","  `iice toond to the horte     `i aon to the more to taak you oo a                                                                                \n","Done.\n"],"name":"stdout"}]}]}