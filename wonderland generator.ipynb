{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de texte avec réseaux de neurones récurrents LSTM avec Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Par : BOUTAHIR Mohamed Khalifa [ MASTER IPS ]\n",
    "##### Data : nous allons utiliser un livre de l'enfance comme Data: \"Alice's Adventures in Wonderland de Lewis Carroll\" . https://gist.github.com/phillipj/4944029\n",
    "##### Le but de projet est de predire une suite où un nouveau scenario pour ce livre .L'utilisation des réseaux LSTM est pour apprendre des séquences de personnages d’Alice au pays des merveilles. Et par la suite le modèle va générer des nouvelles séquences de caractères.\n",
    "<img src=\"wonderland.jpg\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importation des bibliothèques et le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Préparation de l’ensemble de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation du fichier texte et le convertir en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "text = open(filename).read()\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecter les caractères de jeu de donnees et les classer \n",
    " Nous ne pouvons pas modéliser les caractères directement dans le réseau de neurones, nous devons plutôt convertir les caractères en entiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m': 32, 'd': 23, 'l': 31, 't': 39, '\\n': 0, 'r': 37, 'p': 35, '?': 15, '0': 11, 'o': 34, 'x': 43, 'v': 41, '!': 2, 'a': 20, 'k': 30, '(': 5, '\"': 3, 'e': 24, 'n': 33, 'h': 27, '`': 19, 'g': 26, 'z': 45, 'i': 28, \"'\": 4, 'q': 36, ']': 17, ' ': 1, ',': 8, '.': 10, 'j': 29, 'c': 22, 'u': 40, '*': 7, '[': 16, ';': 14, '3': 12, ')': 6, 's': 38, '_': 18, 'f': 25, ':': 13, 'w': 42, 'y': 44, 'b': 21, '-': 9}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcule le nombre total des caractères  de texte et le nombre des caractères "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  148574\n",
      "Total Vocab:  46\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Creation de réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons diviser le texte du livre en sous-séquences d'une longueur fixe de 100 caractères. <br>\n",
    "Chaque modèle d'apprentissage du réseau est composé de 100 pas de temps d'un caractère (X) suivis d'une sortie de caractère (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    seq_out = text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va calculer le nombre des échantillons qu'on dans le \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  148474\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons préparé nos données d’entraînement, nous devons les transformer pour qu’elles puissent être utilisées avec Keras.\n",
    "\n",
    "Nous devons d’abord transformer la liste des séquences d’entrée sous la forme [échantillons, pas de temps, fonctions] pour qu'on puisse les entrés pour notre réseau LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>Platform d'essai</td>\n",
    "        <td>Temps en (s) pour chaque itération</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>GOOGLE COLAB</td>\n",
    "        <td>850s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MY LAPTOP</td>\n",
    "        <td>2000s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>COCALC : https://cocalc.com</td>\n",
    "        <td>5000s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>AZURE NOTEBOOK</td>\n",
    "        <td>24394s</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOGLE COLAB itération : \n",
    "    <img src=\"capture3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AZURE itération :\n",
    "    <img src=\"capture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLALC itération : \n",
    "    <img src=\"capture2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" \n",
      "\n",
      "  just then her head struck against the roof of the hall:  in\n",
      "fact she was now more than nine feet \"\n",
      " hare    `and the ture oi the toies oi the sooel ' \n",
      "  `thet did toe tore the sime!' she manch hare taid to alice, and the tart on thine the was oo the was wottenn to the thet was ano ariel and then so her hend and the tabde so sal at the could, and she taid to she care pateng toiee an the woode and all the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the tooe of the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(500):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
